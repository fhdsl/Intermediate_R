[["index.html", "Intermediate R Chapter 1 About this Course 1.1 Curriculum 1.2 Target Audience 1.3 Offerings", " Intermediate R June, 2024 Chapter 1 About this Course 1.1 Curriculum The course continues building programming fundamentals in R programming and data analysis. You will learn how to make use of complex data structures, use custom functions built by other R users, creating your own functions, and how to iterate repeated tasks that scales naturally. You will also learn how to clean messy data to a Tidy form for analysis, and conduct an end-to-end data science workflow. 1.2 Target Audience The course is intended for researchers who want to continue learning the fundamentals of R programming and how to deal with messy datasets. The audience should know how to subset dataframes and vectors and conduct basic analysis, and/or have taken our Intro to R course. 1.3 Offerings This course is taught on a regular basis at Fred Hutch Cancer Center through the Data Science Lab. Announcements of course offering can be found here. If you wish to follow the course content asynchronously, you may access the course content on this website and exercises and solutions on Posit Cloud. The Posit Cloud compute space can be copied to your own workspace for personal use, and you can get started via this introduction. Or, you can access the exercises and solutions on GitHub. "],["fundamentals.html", "Chapter 2 Fundamentals 2.1 Goals of this course 2.2 Data types in R 2.3 Data structures 2.4 Vector 2.5 Factors 2.6 Dataframes 2.7 Lists 2.8 Matrix 2.9 Exercises", " Chapter 2 Fundamentals Welcome to Intermediate R! Each week, we cover a chapter, which consists of a lesson and exercise. In the first week, we go over the goals of the course, and review data structures and data types that you have seen before from Intro to R. We also look at some new data structures and more properties of data structures. In Intro to R, you learned how to do basic data analysis such as subsetting a dataframe, looking at summary statistics, and visualizing your data. This was done in the context of a clean, Tidy dataframe. In this course, we focus on working with data “from the wild”, in which the data comes in a more messy, un-Tidy form. Let’s see what we will learn in the next 6 weeks together: 2.1 Goals of this course Continue building programming fundamentals: How to use complex data structures, use and create custom functions, and how to iterate repeated tasks. Continue exploration of data science fundamentals: how to clean messy data to a Tidy form for analysis. At the end of the course, you will be able to: conduct a full analysis in the data science workflow (minus model). To get started, let’s recall the fundamental data types in R: 2.2 Data types in R Numeric: 18, -21, 65, 1.25 Character: “ATCG”, “Whatever”, “948-293-0000” Logical: TRUE, FALSE Missing values: NA And the fundamental data structures: in this course, we will learn more about a new, flexible data structure called a List. We also lightly introduce Factor and Matrix, but they will not be used for the rest of the course. 2.3 Data structures Vector Factor Dataframe List Matrix 2.4 Vector We know what an (atomic) vector is: it can contains a data type, and all elements must be the same data type. If a vector consists of only numeric data, then it is a Numeric Vector, etc. We organize vector subtypes by the following graphic: Organization of Vectors. Image Source: Advanced R. Within the Numeric type that we are familiar with, there are more specific types: Integer consists of whole number values, and Double consists of decimal values. Most of the time we only need to consider Numeric types, but once in a while we need to be more specific. Now that we have distinguished vector subtypes, it is important to examine what a vector is by inspection: We can test whether a vector is a certain type with is.___() functions, such as is.character(). is.character(c(&quot;hello&quot;, &quot;there&quot;)) ## [1] TRUE is.character(c(1, 3, 5, 7)) ## [1] FALSE We can also test for missing data NA for any types of vector: The test will return a vector testing each element, because NA can be mixed into other values: is.na(c(34, NA)) ## [1] FALSE TRUE We can coerce vectors from one type to the other with as.___() functions, such as as.numeric(). as.numeric(c(&quot;23&quot;, &quot;45&quot;)) ## [1] 23 45 as.numeric(c(TRUE, FALSE)) ## [1] 1 0 This is very common in data cleaning, when we load in data and they assigned to the wrong data type. Sometimes, a data structure may have metadata attributes associated with them. This gives us more information about the data structure, but doesn’t contain the important data. For instance, a common attribute is names, which can attached to vectors. x = c(1, 2, 3) names(x) = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) x ## a b c ## 1 2 3 Names as an attribute for a Vector. Image Source: Advanced R. We can look for more general attributes beyond names via the attributes() function: attributes(x) ## $names ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; Now, let’s review the ways one can subset a vector. Here are three ways: Positive numeric vector data = c(2, 4, -1, -3, 2, -1, 10) data[c(1, 3, 5)] ## [1] 2 -1 2 Negative numeric vector performs exclusion data[c(-1, -2)] ## [1] -1 -3 2 -1 10 Logical vector data[c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE)] ## [1] 2 -1 2 In practice, we often subset a vector implicitly, via some kind of criteria. Here is a review of implicit subsetting from Intro to R. Let’s review implicit vector subsetting below: How do you subset the following vector so that it only has positive values? data = c(2, 4, -1, -3, 2, -1, 10) data[data &gt; 0] ## [1] 2 4 2 10 How do you subset the following vector so that it has doesn’t have the character “temp”? chars = c(&quot;temp&quot;, &quot;object&quot;, &quot;temp&quot;, &quot;wish&quot;, &quot;bumblebee&quot;, &quot;temp&quot;) chars[chars != &quot;temp&quot;] ## [1] &quot;object&quot; &quot;wish&quot; &quot;bumblebee&quot; How do you subset the following vector so that it has no NA values? vec_with_NA = c(2, 4, NA, NA, 3, NA) vec_with_NA[!is.na(vec_with_NA)] ## [1] 2 4 3 2.5 Factors Factors are a type of vector that holds categorical information, such as sex, gender, or cancer subtype. They are useful for: When you know you have a fixed number of categories. When you want to display character vectors in a non-alphabetical order, which is common in plotting. Inputs for statistical models, as factors are a special type of numerical vectors. Let’s take a look at Factors in practice: place = factor(c(&quot;first&quot;, &quot;third&quot;, &quot;third&quot;, &quot;second&quot;, &quot;second&quot;, &quot;fourth&quot;)) place ## [1] first third third second second fourth ## Levels: first fourth second third df = data.frame(p = place) ggplot(df) + geom_bar(aes(x = p)) We can construct Ordered Factors: place = ordered(c(&quot;first&quot;, &quot;third&quot;, &quot;third&quot;, &quot;second&quot;,&quot;second&quot;, &quot;fourth&quot;), levels = c(&quot;first&quot;, &quot;second&quot;, &quot;third&quot;, &quot;fourth&quot;)) place ## [1] first third third second second fourth ## Levels: first &lt; second &lt; third &lt; fourth df = data.frame(p = place) ggplot(df) + geom_bar(aes(x = p)) 2.6 Dataframes Usually, we load in a Dataframe from a spreadsheet or a package, but we can create a new dataframe by using vectors of the same length via the data.frame() function: df = data.frame(x = 1:3, y = c(&quot;cup&quot;, &quot;mug&quot;, &quot;jar&quot;)) df ## x y ## 1 1 cup ## 2 2 mug ## 3 3 jar We have attributes for Dataframes. The most important attribute is names, which correspond to the column names of a Dataframe. You have been using it for a while already! attributes(df) ## $names ## [1] &quot;x&quot; &quot;y&quot; ## ## $class ## [1] &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 We can directly access the names attribute via names() or colnames(): names(df) ## [1] &quot;x&quot; &quot;y&quot; Here is another example: library(palmerpenguins) attributes(penguins) ## $class ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## [19] 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ## [37] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## [55] 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## [73] 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## [91] 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 ## [109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 ## [127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 ## [145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 ## [163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 ## [181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 ## [199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 ## [217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 ## [235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 ## [253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 ## [271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 ## [289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 ## [307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 ## [325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 ## [343] 343 344 ## ## $names ## [1] &quot;species&quot; &quot;island&quot; &quot;bill_length_mm&quot; ## [4] &quot;bill_depth_mm&quot; &quot;flipper_length_mm&quot; &quot;body_mass_g&quot; ## [7] &quot;sex&quot; &quot;year&quot; Some notes about the other attributes: Sometimes, Dataframes will be in a format called “tibble”, as shown in the penguins class names as “tbl_df”, and “tbl”. Row names are not commonly used. Here is a reason. Let’s review how to subset Dataframes. There are many ways to do it, and here are just some opinionated ways of doing it for this class. Getting one single column: penguins$bill_length_mm ## [1] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42.0 37.8 37.8 41.1 38.6 34.6 ## [16] 36.6 38.7 42.5 34.4 46.0 37.8 37.7 35.9 38.2 38.8 35.3 40.6 40.5 37.9 40.5 ## [31] 39.5 37.2 39.5 40.9 36.4 39.2 38.8 42.2 37.6 39.8 36.5 40.8 36.0 44.1 37.0 ## [46] 39.6 41.1 37.5 36.0 42.3 39.6 40.1 35.0 42.0 34.5 41.4 39.0 40.6 36.5 37.6 ## [61] 35.7 41.3 37.6 41.1 36.4 41.6 35.5 41.1 35.9 41.8 33.5 39.7 39.6 45.8 35.5 ## [76] 42.8 40.9 37.2 36.2 42.1 34.6 42.9 36.7 35.1 37.3 41.3 36.3 36.9 38.3 38.9 ## [91] 35.7 41.1 34.0 39.6 36.2 40.8 38.1 40.3 33.1 43.2 35.0 41.0 37.7 37.8 37.9 ## [106] 39.7 38.6 38.2 38.1 43.2 38.1 45.6 39.7 42.2 39.6 42.7 38.6 37.3 35.7 41.1 ## [121] 36.2 37.7 40.2 41.4 35.2 40.6 38.8 41.5 39.0 44.1 38.5 43.1 36.8 37.5 38.1 ## [136] 41.1 35.6 40.2 37.0 39.7 40.2 40.6 32.1 40.7 37.3 39.0 39.2 36.6 36.0 37.8 ## [151] 36.0 41.5 46.1 50.0 48.7 50.0 47.6 46.5 45.4 46.7 43.3 46.8 40.9 49.0 45.5 ## [166] 48.4 45.8 49.3 42.0 49.2 46.2 48.7 50.2 45.1 46.5 46.3 42.9 46.1 44.5 47.8 ## [181] 48.2 50.0 47.3 42.8 45.1 59.6 49.1 48.4 42.6 44.4 44.0 48.7 42.7 49.6 45.3 ## [196] 49.6 50.5 43.6 45.5 50.5 44.9 45.2 46.6 48.5 45.1 50.1 46.5 45.0 43.8 45.5 ## [211] 43.2 50.4 45.3 46.2 45.7 54.3 45.8 49.8 46.2 49.5 43.5 50.7 47.7 46.4 48.2 ## [226] 46.5 46.4 48.6 47.5 51.1 45.2 45.2 49.1 52.5 47.4 50.0 44.9 50.8 43.4 51.3 ## [241] 47.5 52.1 47.5 52.2 45.5 49.5 44.5 50.8 49.4 46.9 48.4 51.1 48.5 55.9 47.2 ## [256] 49.1 47.3 46.8 41.7 53.4 43.3 48.1 50.5 49.8 43.5 51.5 46.2 55.1 44.5 48.8 ## [271] 47.2 NA 46.8 50.4 45.2 49.9 46.5 50.0 51.3 45.4 52.7 45.2 46.1 51.3 46.0 ## [286] 51.3 46.6 51.7 47.0 52.0 45.9 50.5 50.3 58.0 46.4 49.2 42.4 48.5 43.2 50.6 ## [301] 46.7 52.0 50.5 49.5 46.4 52.8 40.9 54.2 42.5 51.0 49.7 47.5 47.6 52.0 46.9 ## [316] 53.5 49.0 46.2 50.9 45.5 50.9 50.8 50.1 49.0 51.5 49.8 48.1 51.4 45.7 50.7 ## [331] 42.5 52.2 45.2 49.3 50.2 45.6 51.9 46.8 45.7 55.8 43.5 49.6 50.8 50.2 I want to select columns bill_length_mm, bill_depth_mm, species, and filter for species that are “Gentoo”: penguins_select = select(penguins, bill_length_mm, bill_depth_mm, species) penguins_gentoo = filter(penguins_select, species == &quot;Gentoo&quot;) or penguins_select_2 = penguins[, c(&quot;bill_length_mm&quot;, &quot;bill_depth_mm&quot;, &quot;species&quot;)] penguins_gentoo_2 = penguins_select_2[penguins$species == &quot;Gentoo&quot; ,] or penguins_gentoo_2 = penguins_select_2[penguins$species == &quot;Gentoo&quot;, c(&quot;bill_length_mm&quot;, &quot;bill_depth_mm&quot;, &quot;species&quot;)] I want to filter out rows that have NAs in the column bill_length_mm: penguins_clean = filter(penguins, !is.na(bill_length_mm)) or penguins_clean = penguins[!is.na(penguins$bill_depth_mm) ,] 2.7 Lists Lists are the most flexible data structure in R, as they can contain a flexible amount and type of information. They operate similarly as vectors as they group data into one dimension, but each element of a list can be any data type or data structure! l1 = list( 1:3, &quot;a&quot;, c(TRUE, FALSE, TRUE), c(2.3, 5.9) ) Illustration of a List. Image Source: Advanced R. Unlike vectors, you access the elements of a list via the double bracket [[]]. You access a smaller list with single bracket []. (More discussion on the different uses of the bracket here and here.) Use unlist() to coerce a list into a vector. Notice all the automatic coersion that happened for the elements. unlist(l1) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;a&quot; &quot;TRUE&quot; &quot;FALSE&quot; &quot;TRUE&quot; &quot;2.3&quot; &quot;5.9&quot; We can give the attribute names to lists: l1 = list( ranking = 1:3, name = &quot;a&quot;, success = c(TRUE, FALSE, TRUE), score = c(2.3, 5.9) ) #or names(l1) = c(&quot;ranking&quot;, &quot;name&quot;, &quot;success&quot;, &quot;score&quot;) And access named elements of lists via the $ operation: l1$score ## [1] 2.3 5.9 Therefore, l1$score is the same as l1[[4]] and is the same as l1[[\"score\"]]. Here’s an interesting connection between Lists and Dataframes that we will make use of later on in this course: A Dataframe is just a named list of vectors of same length with additional attributes of (column) names and row.names! 2.8 Matrix A matrix holds information of the same data type in two dimensions - it’s like a two dimensional vector. Matricies are most often used in statistical computing and matrix algebra, such as creating a design matrix. They are often created by taking a vector and reshaping it with a set number of rows and columns, or converting from a dataframe with only one data type. my_matrix = matrix(1:10, nrow = 2) my_matrix ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 You access elements of a matrix similar to that of a dataframe’s indexing: #column 3 my_matrix[, 3] ## [1] 5 6 #row 2 my_matrix[2 ,] ## [1] 2 4 6 8 10 #column 3, row 2 my_matrix[2, 3] ## [1] 6 2.9 Exercises You can find exercises and solutions on Posit Cloud, or on GitHub. "],["data-cleaning-part-1.html", "Chapter 3 Data Cleaning, Part 1 3.1 Interpreting functions, carefully 3.2 Recoding Data / Conditionals 3.3 Conditionals 3.4 Exercises", " Chapter 3 Data Cleaning, Part 1 It is often said that 80% of data analysis is spent on the cleaning and preparing data for the analysis. Today we will start looking at common data cleaning tasks, in particular data recoding. In the process, we will be learning a handful of new functions. You already use functions on a regular basis, but for this course, you will be learning how to use other people’s custom functions more independently. Therefore, we start with a review and deeper dive on how to use other people’s custom functions, then we will look at new functions for recoding. 3.1 Interpreting functions, carefully As you become more independent R programmers, you will spend time learning about new functions on your own. We have gone over the basic anatomy of a function call back in Intro to R, but now let’s go a bit deeper to understand how a function is built and how to call them. Recall that a function has a function name, input arguments, and a return value. Function definition consists of assigning a function name with a “function” statement that has a comma-separated list of named function arguments, and a return expression. The function name is stored as a variable in the global environment. In order to use the function, one defines or import it, then one calls it. Example: addFunction = function(num1, num2) { result = num1 + num2 return(result) } result = addFunction(3, 4) When the function is called in line 5, the variables for the arguments are reassigned to function arguments to be used within the function and helps with the modular form. What do you think are some valid inputs for this function? To see why we need the variables of the arguments to be reassigned, consider the following function that is not modular: x = 3 y = 4 addFunction = function(num1, num2) { result = x + y return(result) } result = addFunction(10, -10) Some syntax equivalents on calling the function: addFunction(3, 4) addFunction(num1 = 3, num2 = 4) addFunction(num2 = 4, num1 = 3) but this could be different: addFunction(4, 3) With a deeper knowledge of how functions are built, when you encounter a foreign function, you can look up its help page to understand how to use it. For example, let’s look at mean(): ?mean Arithmetic Mean Description: Generic function for the (trimmed) arithmetic mean. Usage: mean(x, ...) ## Default S3 method: mean(x, trim = 0, na.rm = FALSE, ...) Arguments: x: An R object. Currently there are methods for numeric/logical vectors and date, date-time and time interval objects. Complex vectors are allowed for ‘trim = 0’, only. trim: the fraction (0 to 0.5) of observations to be trimmed from each end of ‘x’ before the mean is computed. Values of trim outside that range are taken as the nearest endpoint. na.rm: a logical evaluating to ‘TRUE’ or ‘FALSE’ indicating whether ‘NA’ values should be stripped before the computation proceeds. ...: further arguments passed to or from other methods. Notice that the arguments trim = 0, na.rm = FALSE have default values. This means that these arguments are optional - you should provide it only if you want to. With this understanding, you can use mean() in a new way: numbers = c(1, 2, NA, 4) mean(x = numbers, na.rm = TRUE) ## [1] 2.333333 The use of . . . (dot-dot-dot): This is a special argument that allows a function to take any number of arguments. This isn’t very useful for the mean() function, but it makes sense for function such as select() and filter(), and mutate(). For instance, in select(), once you provide your dataframe for the argument .data, you can pile on as many columns to select in the rest of the argument. Usage: select(.data, ...) Arguments: .data: A data frame, data frame extension (e.g. a tibble), or a lazy data frame (e.g. from dbplyr or dtplyr). See _Methods_, below, for more details. ...: &lt;‘tidy-select’&gt; One or more unquoted expressions separated by commas. Variable names can be used as if they were positions in the data frame, so expressions like ‘x:y’ can be used to select a range of variables. You will look at the function documentation on your own to see how to deal with more complex cases. 3.2 Recoding Data / Conditionals Suppose that you have a column in your data that needs to be recoded. Since a dataframe’s column, when selected via $, is a vector, let’s start talking about recoding vectors. If we have a numeric vector, then maybe you want to have certain values to be out of bounds, or assign a range of values to a character category. If we have a character vector, then maybe you want to reassign it to a different value. Here are popular recoding logical scenarios: If: “If elements of the vector meets condition, then they are assigned value.” If-else: “If elements of the vector meets condition, then they are assigned value X. Otherwise, they are assigned value Y.” If-else_if-else: “If elements of the vector meets condition A, then they are assigned value X. Else, if the elements of the vector meets condition B, they are assigned value Y. Otherwise, they are assigned value Z.” Let’s look at a vector of grade values, as an example: grade = c(90, 78, 95, 74, 56, 81, 102) If Instead of having the bracket [ ] notation on the right hand side of the equation, if it is on the left hand side of the equation, then we can modify a subset of the vector. grade1 = grade grade1[grade1 &gt; 100] = 100 If-else grade2 = if_else(grade &gt; 60, TRUE, FALSE) If-else_if-else grade3 = case_when(grade &gt;= 90 ~ &quot;A&quot;, grade &gt;= 80 ~ &quot;B&quot;, grade &gt;= 70 ~ &quot;C&quot;, grade &gt;= 60 ~ &quot;D&quot;, .default = &quot;F&quot;) Let’s do it for dataframes now. simple_df = data.frame(grade = c(90, 78, 95, 74, 56, 81, 102), status = c(&quot;case&quot;, &quot; &quot;, &quot;Control&quot;, &quot;control&quot;, &quot;Control&quot;, &quot;Case&quot;, &quot;case&quot;)) If simple_df1 = simple_df simple_df1$grade[simple_df1$grade &gt; 100] = 100 If-else simple_df2 = simple_df simple_df2$grade = ifelse(simple_df2$grade &gt; 60, TRUE, FALSE) or simple_df2 = mutate(simple_df, grade = ifelse(grade &gt; 60, TRUE, FALSE)) If-else_if-else simple_df3 = simple_df simple_df3$grade = case_when(simple_df3$grade &gt;= 90 ~ &quot;A&quot;, simple_df3$grade &gt;= 80 ~ &quot;B&quot;, simple_df3$grade &gt;= 70 ~ &quot;C&quot;, simple_df3$grade &gt;= 60 ~ &quot;D&quot;, .default = &quot;F&quot;) or simple_df3 = simple_df simple_df3 = mutate(simple_df3, grade = case_when(grade &gt;= 90 ~ &quot;A&quot;, grade &gt;= 80 ~ &quot;B&quot;, grade &gt;= 70 ~ &quot;C&quot;, grade &gt;= 60 ~ &quot;D&quot;, .default = &quot;F&quot;)) 3.3 Conditionals The 3 common scenarios we looked at for recoding data is closely tied to the concept of conditionals in programming: given certain conditions, you run a specific code chunk. Given a vector’s value, assign it a different value. Or, given a value, run the following hundred lines of code. Here is what it looks like: If: if(expression_is_TRUE) { #code goes here } If-else: if(expression_is_TRUE) { #code goes here }else { #other code goes here } If-else_if-else: if(expression_A_is_TRUE) { #code goes here }else if(expression_B_is_TRUE) { #other code goes here }else { #some other code goes here } The expression that is being tested whether it is TRUE must be a singular logical value, and not a logical vector. If the latter, see the recoding section for now. Example: nuc = &quot;A&quot; if(nuc == &quot;A&quot;) { nuc = &quot;T&quot; }else if(nuc == &quot;T&quot;) { nuc = &quot;A&quot; }else if(nuc == &quot;C&quot;) { nuc = &quot;C&quot; }else if(nuc == &quot;G&quot;) { nuc = &quot;C&quot; }else { nuc = NA } nuc ## [1] &quot;T&quot; Example: my_input = c(1, 3, 5, 7, 9) #my_input = c(&quot;e&quot;, &quot;e&quot;, &quot;a&quot;, &quot;i&quot;, &quot;o&quot;) if(is.numeric(my_input)) { result = mean(my_input) }else if(is.character(my_input)) { result = table(my_input) } result ## [1] 5 This introduction to conditionals will be more useful when we start writing our functions. 3.4 Exercises You can find exercises and solutions on Posit Cloud, or on GitHub. "],["data-cleaning-part-2.html", "Chapter 4 Data Cleaning, Part 2 4.1 Tidy Data 4.2 Uses of Tidy data 4.3 Subjectivity in Tidy Data 4.4 Exercises", " Chapter 4 Data Cleaning, Part 2 Another important data cleaning step is to make sure that the shape of the data is useful for the analysis. Today, we will learn about a data organizing standard called Tidy Data, and some common transformations of making a dataframe longer and wider to get there. 4.1 Tidy Data It is important to have standard of organizing data, as it facilitates a consistent way of thinking about data organization and building tools (functions) that make use of that standard. The principles of Tidy data, developed by Hadley Wickham: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. If we want to be technical about what variables and observations are, Hadley Wickham describes: A dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes. A Tidy dataframe. Image source: R for Data Science. Besides a standard, Tidy data is useful because many tools in R are most effective when your data is in a Tidy format. This includes data visualization with ggplot, regression models, databases, and more. At first glance, it seems hard to go wrong with these simple criteria of Tidy data! However, in reality, many dataframes we load in aren’t Tidy, and it’s easiest seen through counterexamples and how to fix it. Here are some common ways that data becomes un-Tidy: Columns contain values of variables, rather than variables Variables are stored in rows Multiple variables are stored in a single column After some clear examples, we emphasize that “Tidy” data is subjective to what kind of analysis you want to do with the dataframe. 4.1.1 1. Columns contain values, rather than variables (Long is tidy) df = data.frame(Store = c(&quot;A&quot;, &quot;B&quot;), Year = c(2018, 2018), Q1_Sales = c(55, 98), Q2_Sales = c(45, 70), Q3_Sales = c(22, 60), Q4_Sales = c(50, 60)) df ## Store Year Q1_Sales Q2_Sales Q3_Sales Q4_Sales ## 1 A 2018 55 45 22 50 ## 2 B 2018 98 70 60 60 Each observation is a store, and each observation has its own row. That looks good. The columns “Q1_Sales”, …, “Q4_Sales” seem to be values of a single variable “quarter” of our observation. The values of “quarter” are not in a single column, but are instead in the columns. df_long = pivot_longer(df, c(&quot;Q1_Sales&quot;, &quot;Q2_Sales&quot;, &quot;Q3_Sales&quot;, &quot;Q4_Sales&quot;), names_to = &quot;quarter&quot;, values_to = &quot;sales&quot;) df_long ## # A tibble: 8 × 4 ## Store Year quarter sales ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A 2018 Q1_Sales 55 ## 2 A 2018 Q2_Sales 45 ## 3 A 2018 Q3_Sales 22 ## 4 A 2018 Q4_Sales 50 ## 5 B 2018 Q1_Sales 98 ## 6 B 2018 Q2_Sales 70 ## 7 B 2018 Q3_Sales 60 ## 8 B 2018 Q4_Sales 60 Now, each observation is a store’s quarter, and each observation has its own row. The new columns “quarter” and “sales” are variables that describes our observation, and describes our values. We’re in a tidy state! We have transformed our data to a “longer” format, as our observation represents something more granular or detailed than before. Often, the original variables values will repeat itself in a “longer format”. We call the previous state of our dataframe is a “wider” format. 4.1.2 2. Variables are stored in rows (Wide is tidy) Are all tidy dataframes Tidy in a “longer” format? df2 = data.frame(Sample = c(&quot;A&quot;, &quot;B&quot;), KRAS_mutation = c(TRUE, FALSE), KRAS_expression = c(2.3, 3.9)) df2 ## Sample KRAS_mutation KRAS_expression ## 1 A TRUE 2.3 ## 2 B FALSE 3.9 Each observation is a sample, and each observation has its own row. Looks good. Each variable has its own column, and no values are in columns. What happens if we make it longer? df2_long = pivot_longer(df2, c(&quot;KRAS_mutation&quot;, &quot;KRAS_expression&quot;), names_to = &quot;gene&quot;, values_to = &quot;values&quot;) df2_long ## # A tibble: 4 × 3 ## Sample gene values ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A KRAS_mutation 1 ## 2 A KRAS_expression 2.3 ## 3 B KRAS_mutation 0 ## 4 B KRAS_expression 3.9 Here, each observation is a sample’s gene…type? The observation feels awkward because variables are stored in rows. Also, the column “values” contains multiple variable types: gene expression and mutation values that got coerced to numeric! To make this dataframe wider, df2_long_wide = pivot_wider(df2_long, names_from = &quot;gene&quot;, values_from = &quot;values&quot;) df2_long_wide$KRAS_mutation = as.logical(df2_long_wide$KRAS_mutation) df2_long_wide ## # A tibble: 2 × 3 ## Sample KRAS_mutation KRAS_expression ## &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 A TRUE 2.3 ## 2 B FALSE 3.9 We are back to our orignal form, and it was already Tidy. 4.1.3 3. Multiple variables are stored in a single column table3 ## # A tibble: 6 × 3 ## country year rate ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 There seems to be two variables in the numerator and denominator of “rate” column. Let’s separate it. separate(table3, col = &quot;rate&quot;, into = c(&quot;count&quot;, &quot;population&quot;), sep = &quot;/&quot;) ## # A tibble: 6 × 4 ## country year count population ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 4.2 Uses of Tidy data In general, many functions for analysis and visualization in R assumes that the input dataframe is Tidy. These tools assumes the values of each variable fall in their own column vector. For instance, from our first example, we can compare sales across quarters and stores. df_long ## # A tibble: 8 × 4 ## Store Year quarter sales ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A 2018 Q1_Sales 55 ## 2 A 2018 Q2_Sales 45 ## 3 A 2018 Q3_Sales 22 ## 4 A 2018 Q4_Sales 50 ## 5 B 2018 Q1_Sales 98 ## 6 B 2018 Q2_Sales 70 ## 7 B 2018 Q3_Sales 60 ## 8 B 2018 Q4_Sales 60 ggplot(df_long) + aes(x = quarter, y = sales, group = Store) + geom_point() + geom_line() Although in its original state we can also look at sales between quarter, we can only look between two quarters at once. Tidy data encourages looking at data in the most granular scale. ggplot(df) + aes(x = Q1_Sales, y = Q2_Sales, color = Store) + geom_point() 4.3 Subjectivity in Tidy Data We have looked at clear cases of when a dataset is Tidy. In reality, the Tidy state depends on what we call variables and observations. Consider this example, inspired by the following blog post by Damien Martin. kidney = data.frame(stone_size = c(&quot;Small&quot;, &quot;Large&quot;), treatment.A_recovered = c(81, 192), treatment.A_failed = c(6, 71), treatment.B_recovered = c(234, 55), treatment.B_failed = c(36, 25)) kidney ## stone_size treatment.A_recovered treatment.A_failed treatment.B_recovered ## 1 Small 81 6 234 ## 2 Large 192 71 55 ## treatment.B_failed ## 1 36 ## 2 25 Right now, the kidney dataframe clearly has values of a variable in the column. Let’s try to make it Tidy by making it into a longer form and separating out variables that are together in a column. kidney_long = pivot_longer(kidney, c(&quot;treatment.A_recovered&quot;, &quot;treatment.A_failed&quot;, &quot;treatment.B_recovered&quot;, &quot;treatment.B_failed&quot;), names_to = &quot;treatment_outcome&quot;, values_to = &quot;count&quot;) kidney_long = separate(kidney_long, &quot;treatment_outcome&quot;, c(&quot;treatment&quot;, &quot;outcome&quot;), &quot;_&quot;) kidney_long ## # A tibble: 8 × 4 ## stone_size treatment outcome count ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Small treatment.A recovered 81 ## 2 Small treatment.A failed 6 ## 3 Small treatment.B recovered 234 ## 4 Small treatment.B failed 36 ## 5 Large treatment.A recovered 192 ## 6 Large treatment.A failed 71 ## 7 Large treatment.B recovered 55 ## 8 Large treatment.B failed 25 Here, each observation is a kidney stone’s treatment’s outcome type, and each observation has its own row. The column “count” describes our observation, and describes our values. This dataframe seems reasonably Tidy. How about this? kidney_long_still = pivot_wider(kidney_long, names_from = &quot;outcome&quot;, values_from = &quot;count&quot;) kidney_long_still ## # A tibble: 4 × 4 ## stone_size treatment recovered failed ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Small treatment.A 81 6 ## 2 Small treatment.B 234 36 ## 3 Large treatment.A 192 71 ## 4 Large treatment.B 55 25 Here, each observation is a kidney stone’s treatment, and each observation has its own row. The columns “recovered” and “failed” are variables that describes our observation, and describes its corresponding values. This dataframe seems reasonably Tidy, also. The reason why both of these versions seem Tidy is that the columns “recovered” and “failed” can be interpreted as independent variables and values of the variable “treatment”. Ultimately, we decide which dataframe we prefer based on the analysis we want to do. For instance, when our observation is about a kidney stone’s treatment’s outcome type, we compare it between outcome type, treatment, and stone size. ggplot(kidney_long) + aes(x = treatment, y = count, fill = outcome) + geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + facet_wrap(~stone_size) When our observation is about a kidney stone’s treatment’s, we compare a new variable recovery rate ( = recovered / (recovered + failed)) between treatment and stone size. kidney_long_still = mutate(kidney_long_still, recovery_rate = recovered / (recovered + failed)) ggplot(kidney_long_still) + aes(x = treatment, y = recovery_rate, fill = stone_size) + geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) 4.4 Exercises You can find exercises and solutions on Posit Cloud, or on GitHub. "],["writing-your-first-function.html", "Chapter 5 Writing your first function 5.1 Anatomy of a function definition 5.2 Local and global environments 5.3 A step-by-step example 5.4 Function arguments create modularity 5.5 Examples 5.6 Exercises", " Chapter 5 Writing your first function After learning how to use other people’s functions, it’s time to write our own! We will look at the anatomy of how a function is constructed, and see bunch of examples in action. Function machine from algebra class. First, we remind ourselves why we write functions in the first place. We write functions for two main, often overlapping, reasons: Following DRY (Don’t Repeat Yourself) principle: If you find yourself repeating similar patterns of code, you should write a function that executes that pattern. This saves time and the risk of mistakes. Create modular structure and abstraction: Having all of your code in one place becomes increasingly complicated as your program grows. Think of the function as a mini-program that can perform without the rest of the program. Organizing your code by functions gives modular structure, as well as abstraction: you only need to know the function name, inputs, and output to use it and don’t have to worry how it works. Some advice on writing functions: Code that has a well-defined set of inputs and outputs make a good function. A function should do only one, well-defined task. 5.1 Anatomy of a function definition Function definition consists of assigning a function name with a “function” statement that has a comma-separated list of named function arguments, and a return expression. The function name is stored as a variable in the global environment. In order to use the function, one defines or import it, then one calls it. Example: addFunction = function(argument1, argument2) { result = argument1 + argument2 return(result) } z = addFunction(3, 4) With function definitions, not all code runs from top to bottom. The first four lines defines the function, but the function is never run. It is called on line 5, and the lines within the function are executed. When the function is called in line 5, the variables for the arguments are reassigned to function arguments to be used within the function and helps with the modular form. We need to introduce the concept of local and global environments to distinguish variables used only for a function from variables used for the entire program. 5.2 Local and global environments { } represents variable scoping: within each { }, if variables are defined, they are stored in a local environment, and is only accessible within { }. All function arguments are stored in the local environment. The overall environment of the program is called the global environment and can be also accessed within { }. The reason of having some of this “privacy” in the local environment is to make functions modular - they are independent little tools that should not interact with the rest of the global environment. Imagine someone writing a tool that they want to give someone else to use, but the tool depends on your environment, vice versa. 5.3 A step-by-step example Using the addFunction function, let’s see step-by-step how the R interpreter understands our code: We define the function in the global environment. We call the function, and the function arguments 3, 4 are assigned to argument1 and argument2, respectively in the function’s local environment. We run the first line of code in the function body. The new variable “result” is stored in the local environment because it is within { }. We run the second line of code in the function body to return a value. The return value from the function is assigned to the variable z in the global environment. All local variables for the function are erased now that the function call is over. 5.4 Function arguments create modularity First time writers of functions might ask: why are variables we use for the arguments of a function reassigned for function arguments in the local environment? Here is an example when that process is skipped - what are the consequences? x = 3 y = 4 addFunction = function(argument1, argument2) { result = x + y return(result) } z = addFunction(x, y) w = addFunction(10, -5) What do you expect the value of z to be? How about w? Here is the execution for w: We define the variables and function in the global environment. We call the function, and the function arguments 10, -5 are assigned to argument1 and argument2, respectively in the function’s local environment. We run the first line of code in the function body. The new variable “result” is stored in the local environment because it is within { }. We run the second line of code in the function body to return a value. The return value from the function is assigned to the variable w in the global environment. All local variables for the function are erased now that the function call is over. The function did not work as expected because we used hard-coded variables from the global environment and not function argument variables unique to the function use! 5.5 Examples Create a function, called add_and_raise_power in which the function takes in 3 numeric arguments. The function computes the following: the first two arguments are added together and raised to a power determined by the 3rd argument. The function returns the resulting value. Here is a use case: add_and_raise_power(1, 2, 3) = 27 because the function will return this expression: (1 + 2) ^ 3. Another use case: add_and_raise_power(3, 1, 2) = 16 because of the expression (3 + 1) ^ 2. Confirm with that these use cases work. Can this function used for numeric vectors? add_and_raise_power = function(x, y, z) { result = (x + y)^z return(result) } add_and_raise_power(1, 2, 3) ## [1] 27 Create a function, called my_dim in which the function takes in one argument: a dataframe. The function returns the following: a length-2 numeric vector in which the first element is the number of rows in the dataframe, and the second element is the number of columns in the dataframe. Your result should be identical as the dim function. How can you leverage existing functions such as nrow and ncol? Use case: my_dim(penguins) = c(344, 8) library(palmerpenguins) my_dim = function(df) { result = c(nrow(df), ncol(df)) return(result) } my_dim(penguins) ## [1] 344 8 Create a function, called num_na in which the function takes in any vector, and then return a single numeric value. This numeric value is the number of NAs in the vector. Use cases: num_na(c(NA, 2, 3, 4, NA, 5)) = 2 and num_na(c(2, 3, 4, 5)) = 0. Hint 1: Use is.na() function. Hint 2: Given a logical vector, you can count the number of TRUE values by using sum(), such as sum(c(TRUE, TRUE, FALSE)) = 2. num_na = function(x) { return(sum(is.na(num_na))) } Create a function, called medicaid_eligible in which the function takes in one argument: a numeric vector called age. The function returns a numeric vector with the same length as age, in which elements are 0 for indicies that are less than 65 in age, and 1 for indicies 65 or higher in age. (Hint: This is a data recoding problem!) Use cases: medicaid_eligible(c(30, 70)) = c(0, 1) medicaid_eligible = function(age) { result = age result[age &lt; 65] = 0 result[age &gt;= 65] = 1 return(result) } medicaid_eligible(c(30, 70)) ## [1] 0 1 5.6 Exercises You can find exercises and solutions on Posit Cloud, or on GitHub. "],["iteration.html", "Chapter 6 Iteration 6.1 For loops 6.2 Functionals 6.3 Case studies 6.4 Exercises", " Chapter 6 Iteration Suppose that you want to repeat a chunk of code many times, but changing one variable’s value each time you do it. This could be modifying each element of a vector with the same operation, or analyzing a dataframe with different parameters. There are three common strategies to go about this: Copy and paste the code chunk, and change that variable’s value. Repeat. This can be a starting point in your analysis, but will lead to errors easily. Use a for loop to repeat the chunk of code, and let it loop over the changing variable’s value. This is popular for many programming languages, but the R programming culture encourages a functional way instead. Functionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. This is very popular in R programming culture. 6.1 For loops A for loop repeats a chunk of code many times, once for each element of an input vector. for (my_element in my_vector) { chunk of code } Most often, the “chunk of code” will make use of my_element. 6.1.0.1 We can loop through the indicies of a vector The function seq_along() creates the indicies of a vector. It has almost the same properties as 1:length(my_vector), but avoids issues when the vector length is 0. my_vector = c(1, 3, 5, 7) for(i in seq_along(my_vector)) { print(my_vector[i]) } ## [1] 1 ## [1] 3 ## [1] 5 ## [1] 7 6.1.0.2 Alternatively, we can loop through the elements of a vector for(vec_i in my_vector) { print(vec_i) } ## [1] 1 ## [1] 3 ## [1] 5 ## [1] 7 6.1.0.3 Another example via indicies result = rep(NA, length(my_vector)) for(i in seq_along(my_vector)) { result[i] = log(my_vector[i]) } 6.2 Functionals A functional is a function that takes in a data structure and function as inputs and applies the function on the data structure, element by element. It maps your input data structure to an output data structure based on the function. It encourages the usage of modular functions in your code. Or, We will use the purrr package in tidyverse to use functionals. There is another set of functionals in Base-R called the apply family of functions that work very similarly. You can see the comparision of both tools here and here. map() takes in a vector or a list, and then applies the function on each element of it. The output is always a list. my_vector = c(1, 3, 5, 7) map(my_vector, log) ## [[1]] ## [1] 0 ## ## [[2]] ## [1] 1.098612 ## ## [[3]] ## [1] 1.609438 ## ## [[4]] ## [1] 1.94591 Lists are useful if what you are using it on requires a flexible data structure. To be more specific about the output type, you can do this via the map_* function, where * specifies the output type: map_lgl(), map_chr(), and map_dbl() functions return vectors of logical values, strings, or numbers respectively. For example, to make sure your output is a double (numeric): map_dbl(my_vector, log) ## [1] 0.000000 1.098612 1.609438 1.945910 All of these are toy examples that gets us familiar with the syntax, but we already have built-in functions to solve these problems, such as log(my_vector). Let’s see some real-life case studies. 6.3 Case studies 6.3.1 1. Loading in multiple files. Suppose that we want to load in a few dataframes, and store them in a list of dataframes for analysis downstream. We start with the filepaths we want to load in as dataframes. paths = c(&quot;classroom_data/students.csv&quot;, &quot;classroom_data/CCLE_metadata.csv&quot;) The function we want to use to load the data in will be read_csv(). Let’s practice writing out one iteration: result = read_csv(paths[1]) 6.3.1.1 To do this functionally, we think about: What variable we need to loop through: paths The repeated task as a function: read_csv() The looping mechanism, and its output: map() outputs lists. loaded_dfs = map(paths, read_csv) 6.3.1.2 To do this with a for loop, we think about: What variable we need to loop through: paths. Do we need to store the outcome of this loop in a data structure? Yes, a list. At each iteration, what are we doing? Use read_csv() on the current element, and store it in the output list. paths = c(&quot;classroom_data/students.csv&quot;, &quot;classroom_data/CCLE_metadata.csv&quot;) loaded_dfs = vector(mode = &quot;list&quot;, length = length(paths)) for(i in seq_along(paths)) { df = read_csv(paths[i]) loaded_dfs[[i]] = df } 6.3.2 2. Analyze a dataframe with different parameters. Suppose you are working with the penguins dataframe: library(palmerpenguins) head(penguins) ## # A tibble: 6 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; and you want to look at the mean bill_length_mm for each of the three species (Adelie, Chinstrap, Gentoo). Let’s practice writing out one iteration: species_to_analyze = c(&quot;Adelie&quot;, &quot;Chinstrap&quot;, &quot;Gentoo&quot;) penguins_subset = filter(penguins, species == species_to_analyze[1]) mean(penguins_subset$bill_length_mm, na.rm = TRUE) ## [1] 38.79139 6.3.2.1 To do this functionally, we think about: What variable we need to loop through: c(\"Adelie\", \"Chinstrap\", \"Gentoo\") The repeated task as a function: a custom function that takes in a specie of interest. The function filters the rows of penguins to the species of interest, and compute the mean of bill_length_mm. The looping mechanism, and its output: map_dbl() outputs (double) numeric vectors. analysis = function(current_species) { penguins_subset = dplyr::filter(penguins, species == current_species) return(mean(penguins_subset$bill_length_mm, na.rm=TRUE)) } map_dbl(c(&quot;Adelie&quot;, &quot;Chinstrap&quot;, &quot;Gentoo&quot;), analysis) ## [1] 38.79139 48.83382 47.50488 6.3.2.2 To do this with a for loop, we think about: What variable we need to loop through: c(\"Adelie\", \"Chinstrap\", \"Gentoo\"). Do we need to store the outcome of this loop in a data structure? Yes, a numeric vector. At each iteration, what are we doing? Filter the rows of penguins to the species of interest, and compute the mean of bill_length_mm. outcome = rep(NA, length(species_to_analyze)) for(i in seq_along(species_to_analyze)) { penguins_subset = filter(penguins, species == species_to_analyze[i]) outcome[i] = mean(penguins_subset$bill_length_mm, na.rm=TRUE) } outcome ## [1] 38.79139 48.83382 47.50488 6.3.3 3. Calculate summary statistics on columns of a dataframe. Suppose that you are interested in the numeric columns of the penguins dataframe. penguins_numeric = penguins %&gt;% select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) and you are interested to look at the mean of each column. It is very helpful to interpret the dataframe penguins_numeric as a list, iterating through each column as an element of a list. Let’s practice writing out one iteration: mean(penguins_numeric[[1]], na.rm = TRUE) ## [1] 43.92193 6.3.3.1 To do this functionally, we think about: What variable we need to loop through: the list penguins_numeric The repeated task as a function: mean() with the argument na.rm = TRUE. The looping mechanism, and its output: map_dbl() outputs (double) numeric vectors. map_dbl(penguins_numeric, mean, na.rm = TRUE) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92193 17.15117 200.91520 4201.75439 Here, R is interpreting the dataframe penguins_numeric as a list, iterating through each column as an element of a list: 6.3.3.2 To do this with a for loop, we think about: What variable we need to loop through: the elements of penguins_numeric as a list. Do we need to store the outcome of this loop in a data structure? Yes, a numeric vector. At each iteration, what are we doing? Compute the mean of an element of penguins_numeric. result = rep(NA, ncol(penguins_numeric)) for(i in seq_along(penguins_numeric)) { result[i] = mean(penguins_numeric[[i]], na.rm = TRUE) } result ## [1] 43.92193 17.15117 200.91520 4201.75439 6.4 Exercises You can find exercises and solutions on Posit Cloud, or on GitHub. "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Lead Content Instructor(s) Chris Lo Lecturer Chris Lo Content Author(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved If any other authors besides lead instructor Content Contributor(s) (include section name/link in parentheses) - make new line if more than one section involved Wrote less than a chapter Content Editor(s)/Reviewer(s) Checked your content Content Director(s) Helped guide the content direction Content Consultants (include chapter name/link in parentheses or word “General”) - make new line if more than one chapter involved Gave high level advice on content Acknowledgments Gave small assistance to content but not to the level of consulting Production Content Publisher(s) Helped with publishing platform Content Publishing Reviewer(s) Reviewed overall content and aesthetics on publishing platform Technical Course Publishing Engineer(s) Helped with the code for the technical aspects related to the specific course generation Template Publishing Engineers Candace Savonen, Carrie Wright, Ava Hoffman Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Ava Hoffman, Candace Savonen Package Developers (ottrpal) Candace Savonen, John Muschelli, Carrie Wright Art and Design Illustrator(s) Created graphics for the course Figure Artist(s) Created figures/plots for course Videographer(s) Filmed videos Videography Editor(s) Edited film Audiographer(s) Recorded audio Audiography Editor(s) Edited audio recordings Funding Funder(s) Institution/individual who funded course including grant number Funding Staff Staff members who help with funding   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.2 (2023-10-31) ## os Ubuntu 22.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2024-06-17 ## pandoc 3.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## bookdown 0.39.1 2024-06-11 [1] Github (rstudio/bookdown@f244cf1) ## bslib 0.6.1 2023-11-28 [1] RSPM (R 4.3.0) ## cachem 1.0.8 2023-05-01 [1] RSPM (R 4.3.0) ## cli 3.6.2 2023-12-11 [1] RSPM (R 4.3.0) ## devtools 2.4.5 2022-10-11 [1] RSPM (R 4.3.0) ## digest 0.6.34 2024-01-11 [1] RSPM (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [1] RSPM (R 4.3.0) ## evaluate 0.23 2023-11-01 [1] RSPM (R 4.3.0) ## fastmap 1.1.1 2023-02-24 [1] RSPM (R 4.3.0) ## fs 1.6.3 2023-07-20 [1] RSPM (R 4.3.0) ## glue 1.7.0 2024-01-09 [1] RSPM (R 4.3.0) ## htmltools 0.5.7 2023-11-03 [1] RSPM (R 4.3.0) ## htmlwidgets 1.6.4 2023-12-06 [1] RSPM (R 4.3.0) ## httpuv 1.6.14 2024-01-26 [1] RSPM (R 4.3.0) ## jquerylib 0.1.4 2021-04-26 [1] RSPM (R 4.3.0) ## jsonlite 1.8.8 2023-12-04 [1] RSPM (R 4.3.0) ## knitr 1.47.3 2024-06-11 [1] Github (yihui/knitr@e1edd34) ## later 1.3.2 2023-12-06 [1] RSPM (R 4.3.0) ## lifecycle 1.0.4 2023-11-07 [1] RSPM (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] RSPM (R 4.3.0) ## memoise 2.0.1 2021-11-26 [1] RSPM (R 4.3.0) ## mime 0.12 2021-09-28 [1] RSPM (R 4.3.0) ## miniUI 0.1.1.1 2018-05-18 [1] RSPM (R 4.3.0) ## pkgbuild 1.4.3 2023-12-10 [1] RSPM (R 4.3.0) ## pkgload 1.3.4 2024-01-16 [1] RSPM (R 4.3.0) ## profvis 0.3.8 2023-05-02 [1] RSPM (R 4.3.0) ## promises 1.2.1 2023-08-10 [1] RSPM (R 4.3.0) ## purrr 1.0.2 2023-08-10 [1] RSPM (R 4.3.0) ## R6 2.5.1 2021-08-19 [1] RSPM (R 4.3.0) ## Rcpp 1.0.12 2024-01-09 [1] RSPM (R 4.3.0) ## remotes 2.4.2.1 2023-07-18 [1] RSPM (R 4.3.0) ## rlang 1.1.4 2024-06-04 [1] CRAN (R 4.3.2) ## rmarkdown 2.27.1 2024-06-11 [1] Github (rstudio/rmarkdown@e1c93a9) ## sass 0.4.8 2023-12-06 [1] RSPM (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.3.0) ## shiny 1.8.0 2023-11-17 [1] RSPM (R 4.3.0) ## stringi 1.8.3 2023-12-11 [1] RSPM (R 4.3.0) ## stringr 1.5.1 2023-11-14 [1] RSPM (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] RSPM (R 4.3.0) ## usethis 2.2.3 2024-02-19 [1] RSPM (R 4.3.0) ## vctrs 0.6.5 2023-12-01 [1] RSPM (R 4.3.0) ## xfun 0.44.4 2024-06-11 [1] Github (yihui/xfun@9da62cc) ## xtable 1.8-4 2019-04-21 [1] RSPM (R 4.3.0) ## yaml 2.3.8 2023-12-11 [1] RSPM (R 4.3.0) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────── "],["references.html", "Chapter 7 References", " Chapter 7 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
